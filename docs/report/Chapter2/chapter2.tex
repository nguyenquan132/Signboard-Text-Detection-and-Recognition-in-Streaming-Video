\chapter{CƠ SỞ LÝ THUYẾT VÀ PHƯƠNG PHÁP TIẾP CẬN}

\ifpdf
    \graphicspath{{Chapter2/Chapter2Figs/PNG/}{Chapter2/Chapter2Figs/PDF/}{Chapter2/Chapter2Figs/Chapter2Figs/}}
\else
    \graphicspath{{Chapter2/Chapter2Figs/EPS/}{Chapter2/Chapter2Figs/}}
\fi

\markboth{\MakeUppercase{\thechapter. Cơ sở lý thuyết và phương pháp tiếp cận}}{\thechapter. Cơ sở lý thuyết và phương pháp tiếp cận}

\section{Phát hiện đối tượng}
\subsection{Cơ sở và hướng tiếp cận chung}
Phát hiện đối tượng (Object Detection) là một bài toán trong lĩnh vực Thị giác Máy
tính (Computer Vision), đóng vai trò trung tâm trong nhiều ứng dụng thực tiễn như giám
sát an ninh, lái xe tự động, và tương tác người máy. Khác với nhiệm vụ phân loại ảnh
truyền thống vốn chỉ xác định loại đối tượng xuất hiện trong toàn bộ ảnh, phát hiện đối
tượng yêu cầu mô hình không chỉ nhận diện đúng loại đối tượng mà còn xác định chính
xác vị trí của chúng thông qua các hộp giới hạn (bounding boxes). Thách thức của bài
toán này nằm ở việc phải xử lý đồng thời nhiều đối tượng với sự đa dạng lớn về kích
thước, tư thế, góc nhìn, điều kiện ánh sáng và mức độ chồng lấn giữa các đối tượng.

Dựa trên tổng quan của \cite{zou2023object}, các phương pháp phát hiện đối tượng hiện đại có thể được phân loại thành ba hướng tiếp cận chính xét theo kiến trúc và quy trình xử lý: 

\begin{itemize}
    \item \textbf{Các phương pháp hai giai đoạn (Two-stage)} hoạt động dựa trên nguyên tắc tách biệt quá trình đề xuất vùng (region proposal) và phân loại. Nhóm này tiêu biểu bởi các mô hình thuộc họ R-CNN, chẳng hạn như R-CNN \cite{girshick2014rich}, Fast R-CNN \cite{girshick2015fast} và Faster R-CNN \cite{ren2015faster}. Các phương pháp này thường đạt độ chính xác cao nhưng đòi hỏi chi phí tính toán lớn và tốc độ xử lý chậm.
    \item \textbf{Các phương pháp một giai đoạn (One-stage)} thực hiện trực tiếp việc dự đoán lớp và vị trí mà không có bước đề xuất vùng riêng biệt, với các đại diện nổi bật như YOLO \cite{redmon2016you}, SSD \cite{liu2016ssd} và RetinaNet \cite{lin2017focal}. Cách tiếp cận này giúp cân bằng tốt hơn giữa tốc độ và độ chính xác, phù hợp với các ứng dụng thời gian thực.
    \item \textbf{Các phương pháp dựa trên Transformer} gần đây tạo ra bước đột phá với kiến trúc end-to-end, loại bỏ sự phụ thuộc vào các thành phần được thiết kế thủ công (hand-crafted) như anchor và thuật toán Non-Maximum Suppression (NMS). Điển hình cho hướng đi này là mô hình DETR \cite{carion2020end} và các biến thể tối ưu hóa tốc độ của nó.
\end{itemize}
\subsection{Phương pháp tiếp cận}

Trong bối cảnh của khóa luận này, bài toán phát hiện biển hiệu đòi hỏi sự cân bằng giữa tốc độ xử lý, độ chính xác và khả năng xử lý các đối tượng có hướng (oriented objects). Vì vậy, khóa luận tập trung lựa chọn và đánh giá một số phương pháp tiên tiến hiện nay, tiêu biểu cho các hướng tiếp cận khác nhau, dựa trên mức độ phù hợp với các yêu cầu của bài toán.

\begin{itemize}
    \item \textbf{YOLO (You Only Look Once) \cite{redmon2016you}:} YOLO là đại diện tiêu biểu cho hướng tiếp cận một giai đoạn (one-stage). Kiến trúc của YOLO dựa trên việc chia ảnh đầu vào thành một lưới (grid), mỗi ô lưới chịu trách nhiệm dự đoán đồng thời các bounding box và xác suất lớp. Cách tiếp cận trực tiếp này mang lại tốc độ suy luận rất cao, phù hợp cho các ứng dụng thời gian thực. Đặc biệt, biến thể YOLO-OBB (Oriented Bounding Box) mở rộng khả năng phát hiện vật thể xoay, là một lựa chọn rất phù hợp cho bài toán phát hiện biển hiệu.
    \item \textbf{DETR (DEtection TRansformer) \cite{carion2020end}:} DETR là mô hình phát hiện đối tượng đầu tiên hoàn toàn dựa trên kiến trúc Transformer. Mô hình sử dụng một tập hợp cố định các "truy vấn" (object queries) để tương tác với đặc trưng hình ảnh và dự đoán trực tiếp một tập các bounding box, nhờ đó loại bỏ hoàn toàn nhu cầu về các thành phần thủ công như anchor boxes và NMS.
    \item \textbf{RTDETRv2 \cite{zhao2024detrs}:} RT-DETRv2 là phiên bản cải tiến từ RT-DETR, được đề xuất với mục tiêu tối ưu hóa hiệu suất thời gian thực (real-time performance) trong khi vẫn duy trì độ chính xác cao. Mô hình này giữ nguyên ưu điểm end-to-end của DETR, loại bỏ sự phụ thuộc vào NMS, và được tối ưu hóa thông qua các cơ chế như hybrid encoder cùng cơ chế lựa chọn truy vấn (query selection) nhằm cân bằng giữa độ chính xác và hiệu quả tính toán.

\end{itemize}

Bên cạnh các phương pháp phát hiện trực tiếp dựa trên bounding box, để mở rộng góc nhìn đánh giá, khóa luận xem xét một hướng tiếp cận gián tiếp thông qua bài toán phân đoạn ngữ nghĩa (semantic segmentation). Theo hướng tiếp cận này, đối tượng trước hết được phân đoạn ở mức điểm ảnh, từ đó suy ra vùng bao hình học của đối tượng, phục vụ cho bài toán phát hiện. Trong bối cảnh đó, theo tổng quan của \cite{vat_survey}, các kiến trúc dựa trên Transformer đã trở thành một hướng tiếp cận được quan tâm rộng rãi và ngày càng quan trọng trong bài toán phân đoạn ảnh, đặc biệt là phân đoạn ngữ nghĩa. Nhờ khả năng mô hình hóa ngữ cảnh toàn cục thông qua cơ chế self-attention, các mô hình này cho thấy hiệu quả nổi bật trong việc xử lý các kịch bản có cấu trúc phức tạp và sự đa dạng lớn về hình dạng đối tượng.

\begin{itemize}
    \item \textbf{SegFormer \cite{xie2021segformer}:} SegFormer là một kiến trúc phân đoạn ngữ nghĩa hiệu quả dựa trên Transformer, kết hợp giữa encoder Transformer phân cấp và decoder MLP nhẹ. Thiết kế này cho phép mô hình khai thác ngữ cảnh toàn cục thông qua self-attention, đồng thời duy trì hiệu quả tính toán cao nhờ cấu trúc decoder đơn giản. Nhờ đó, SegFormer đạt được sự cân bằng tốt giữa độ chính xác và tốc độ suy luận, phù hợp với các ứng dụng phân đoạn ngữ nghĩa trong bối cảnh thực tế.
    \item \textbf{Mask2Former \cite{cheng2022masked}:} Mask2Former là một kiến trúc phân đoạn dựa trên Transformer theo hướng tiếp cận thống nhất (unified framework), có khả năng xử lý nhiều bài toán phân đoạn khác nhau như phân đoạn ngữ nghĩa (semantic segmentation), phân đoạn theo thể hiện (instance segmentation) và phân đoạn toàn cảnh (panoptic segmentation). Mask2Former áp dụng cơ chế masked attention, cho phép mô hình tập trung vào các vùng đối tượng tiềm năng thông qua các mask dự đoán, từ đó cải thiện khả năng biểu diễn hình dạng và biên đối tượng. Cách tiếp cận này giúp Mask2Former thể hiện hiệu quả trên các trường hợp có đối tượng chồng lấn hoặc hình dạng phức tạp.
\end{itemize}

\section{Phát hiện và nhận dạng văn bản ngoại cảnh (Scene Text Detection and Recogntion)}
\subsection{Phát hiện văn bản ngoại cảnh (Scene Text Detection)}
\subsubsection{Cơ sở và hướng tiếp cận chung}
Phát hiện văn bản (Text Detection) trong ảnh ngoại cảnh hướng tới mục tiêu xác định và khoanh vùng các khu vực chứa văn bản. Khác với các tác vụ phát hiện đối tượng truyền thống, phát hiện văn bản trong ảnh ngoại cảnh phải đối mặt với nhiều thách thức do sự đa dạng về hình dạng, kích thước, hướng và bố cục của văn bản, cũng như các trường hợp văn bản bị nghiêng, cong, chồng chéo hoặc mờ.  Do đó, bài toán này đòi hỏi kết hợp các kỹ thuật phát hiện đối tượng với các phương pháp chuyên biệt cho văn bản nhằm xác định chính xác và hiệu quả các vùng chứa văn bản.

Dựa trên các nghiên cứu khảo sát gần đây \cite{kang2022overview, pal2024comprehensive, han2024spotlight} về phát hiện văn bản trong ảnh ngoại cảnh, các phương pháp tiên tiến hiện nay có thể được phân thành ba hướng tiếp cận chính: dựa trên hồi quy (regression-based), dựa trên phân đoạn (segmentation-based) và dựa trên thành phần liên thông (connected component-based).

\begin{itemize}
    \item \textbf{Các phương pháp dựa trên hồi quy (Regression-based):} Hướng tiếp cận này giải quyết bài toán phát hiện văn bản tương tự như phát hiện đối tượng, bằng cách trực tiếp dự đoán tọa độ các vùng văn bản dưới dạng hộp chữ nhật hoặc đa giác. Nhờ kiến trúc tối ưu cho việc dự đoán tọa độ, các phương pháp này thường có tốc độ suy luận nhanh, phù hợp với các ứng dụng thời gian thực.Tuy nhiên, một hạn chế chung của hướng tiếp cận này là thường yêu cầu các bước hậu xử lý (post-processing) phức tạp, đồng thời gặp khó khăn khi xử lý văn bản cong hoặc có hình dạng phức tạp. Một số phương pháp tiên tiến theo hướng này bao gồm TextBoxes \cite{liao2017textboxes}, EAST \cite{zhou2017east}, FCE-Net \cite{zhu2021fourier}, ABCNet \cite{liu2020abcnet}.
    \item \textbf{Các phương pháp dựa trên thành phần liên thông (Connected Component-based):} Các hương pháp này tập trung vào việc phát hiện và nhóm các thành phần ảnh có đặc trưng tương đồng (như màu sắc, kết cấu hoặc cường độ) để hình thành các vùng văn bản hoàn chỉnh. Hướng tiếp cận này đạt hiệu quả trong các trường hợp đơn giản nhưng thường kém hiệu quả khi gặp nền phức tạp, văn bản cong hoặc có hình dạng phức tạp. Đồng thời, việc nhóm các thành phần riêng lẻ cũng đòi hỏi các bước hậu xử lý phức tạp để tái cấu trúc văn bản. Một số phương pháp tiêu biểu trong nhóm này gồm TextSnake \cite{long2018textsnake}, DRRG \cite{zhang2020deep}.
    \item \textbf{Các phương pháp dựa trên phân đoạn (Segmentation-based):} Nhóm phương pháp này xem phát hiện văn bản như một bài toán phân đoạn mức pixel, trong đó mỗi pixel được phân loại là văn bản hoặc nền. Từ kết quả phân đoạn, các vùng văn bản được suy ra và phục hồi thông qua các bước hậu xử lý. Cách tiếp cận này cho phép xử lý hiệu quả các văn bản có hình dạng phi chuẩn, như văn bản cong hoặc nghiêng, nhưng thường tốn kém tính toán hơn. Một số phương pháp tiên tiến hiên này với hướng tiếp cận này bao gồm PANet \cite{liu2018path}, DBNet++ \cite{liao2022real}, TextPMs \cite{zhang2022arbitrary}, FAST \cite{chen2021fast} và KPN \cite{zhang2022kernel}.
\end{itemize}

\subsubsection{Phương pháp tiếp cận}
Trong bối cảnh đầy thách thức của phát hiện văn bản trên biển hiệu thực tế, khóa luận lựa chọn một số phương pháp tiên tiến hiện nay nhằm đánh giá khả năng xử lý các văn bản có hình dạng đa dạng. Những phương pháp này có khả năng duy trì độ chính xác đồng thời giảm thiểu các bước hậu xử lý phức tạp. Việc đánh giá các mô hình không chỉ giúp so sánh hiệu quả giữa các giải pháp hiện nay, mà còn cung cấp cái nhìn tổng quan về những hướng tiếp cận khả thi cho bài toán.

\begin{itemize}
    \item \textbf{PANet \cite{liu2018path}:} PANet là một kiến trúc phân đoạn hiệu quả với hai thành phần chính gồm Feature Pyramid Enhancement Module (FPEM), chịu trách nhiệm tạo bản đồ đặc trưng đa tỷ lệ, và Feature Fusion Module (FFM), thực hiện tổng hợp các đặc trưng này. Bằng cách áp dụng phương pháp pixel aggregation trên bản đồ đặc trưng cuối cùng, PANet có thể nhóm chính xác các pixel văn bản vào các thể hiện tương ứng, đạt hiệu quả cao nhờ quy trình phân đoạn có chi phí tính toán thấp.
    \item \textbf{DBNet \cite{liao2022real}:} DBNet++ là phiên bản cải tiến của DBNet, tích hợp cơ chế differentiable binarization (DB) trực tiếp vào mạng phân đoạn để tạo mask văn bản chính xác và ổn định, giảm đáng kể các bước hậu xử lý. Đồng thời, Adaptive Scale Fusion (ASF) được áp dụng để hợp nhất các đặc trưng đa tỷ lệ, cải thiện khả năng xử lý các văn bản có kích thước khác nhau.
    \item \textbf{TextPMs \cite{zhang2022arbitrary}:}
    \item \textbf{FAST \cite{chen2021fast}:}
    \item \textbf{KPN \cite{zhang2022kernel}:}
\end{itemize}

\subsection{Nhận dạng văn bản (Text Recognition)}
\subsubsection{Cơ sở và hướng tiếp cận chung}
\subsubsection{Phương pháp tiếp cận}

\subsection{End-to-End (End-to-End Text Recognition)}
\subsubsection{Cơ sở và hướng tiếp cận chung}
\subsubsection{Phương pháp tiếp cận}

% \section{Giới thiệu}

% \subsection{Tổng quan và ý nghĩa thực tiễn của bài toán phát hiện và nhận dạng văn bản trên biển hiệu trong video đường phố Việt Nam}
% Trong môi trường giao thông đô thị, biển hiệu và bảng quảng cáo (signboards) là nguồn thông tin quan trọng phản ánh danh tính địa điểm (tên cửa hàng), cũng như loại sản phẩm/dịch vụ mà địa điểm đó cung cấp.
% Với dữ liệu video quay từ camera hành trình, hệ thống ``đọc văn bản trong cảnh'' (scene text reading) có thể hỗ trợ nhiều ứng dụng thực tế như:
% (i) lập bản đồ/định vị theo ngữ nghĩa (semantic mapping), (ii) tìm kiếm địa điểm theo từ khóa (place search),
% (iii) thống kê loại hình kinh doanh theo khu vực, và (iv) hỗ trợ nhận thức tình huống trong các hệ thống giao thông thông minh.

% Bài toán trong khóa luận tập trung vào xây dựng một pipeline tích hợp gồm:
% \begin{itemize}
%     \item \textbf{Phát hiện (Text Detection):} xác định và khoanh vùng các vùng chứa văn bản trong từng khung hình.
%     \item \textbf{Nhận dạng (Text Recognition):} chuyển đổi ảnh vùng chữ thành chuỗi ký tự.
% \end{itemize}

% \subsection{Thách thức về tính đa dạng và phức tạp của văn bản trong môi trường tự nhiên}
% Khác với tài liệu quét (scanned documents), văn bản trong cảnh đường phố thường xuất hiện trong điều kiện chụp không kiểm soát.
% Các thách thức nổi bật bao gồm:
% \begin{itemize}
%     \item \textbf{Nền phức tạp (cluttered background):} nhiều vật thể/hoa văn gây nhiễu.
%     \item \textbf{Văn bản biến dạng:} chữ cong/nghiêng/méo do phối cảnh, bề mặt biển hiệu hoặc góc nhìn.
%     \item \textbf{Đa dạng phông chữ và kích thước:} font stylized, độ dày nét khác nhau, chữ rất nhỏ hoặc rất lớn.
%     \item \textbf{Đa ngôn ngữ và dấu:} tiếng Việt có dấu, có thể xen kẽ tiếng Anh/Trung/Hàn; dấu câu đa dạng.
%     \item \textbf{Motion blur và out-of-focus:} do xe di chuyển, rung camera, tốc độ cao.
%     \item \textbf{Độ phân giải thấp (low resolution):} chữ nhỏ, ở xa camera, nén video làm mất chi tiết.
% \end{itemize}

% \subsubsection{Bài toán Scene Text Detection and Recognition}
% Tổng quát, bài toán Scene Text Reading có thể được tiếp cận theo ba hướng chính:
% \begin{enumerate}
%     \item \textbf{Text Detection:} chỉ dự đoán vị trí vùng chữ (bounding box / polygon / mask).
%     \item \textbf{Text Recognition:} nhận dạng ký tự/chuỗi ký tự từ các vùng chữ đã được cắt sẵn.
%     \item \textbf{End-to-End Text Spotting/Recognition:} kết hợp phát hiện và nhận dạng trong một pipeline thống nhất.
% \end{enumerate}
% Trong khóa luận, trọng tâm là xây dựng pipeline tích hợp cho dữ liệu street-view/video, ưu tiên nhóm đối tượng biển hiệu/bảng quảng cáo cửa hàng.

% \subsubsection{Phân loại hướng tiếp cận cho bài toán Text Detection and Recognition}
% Các phương pháp học sâu cho bài toán đọc văn bản trong ảnh ngoại cảnh (scene text reading) thường được phân nhóm theo phạm vi xử lý:
% (i) chỉ phát hiện vùng chữ, (ii) chỉ nhận dạng chữ trên vùng cắt sẵn, hoặc (iii) pipeline end-to-end kết hợp cả hai.

% \begin{figure}[t]
%     \centering
%     \includegraphics[width=0.98\linewidth]{text_detection_recognition_taxonomy.png}
%     \caption{Phân nhóm các phương pháp cho bài toán Text Detection and Recognition trong ảnh ngoại cảnh.}
%     \label{fig:text_detection_recognition_taxonomy}
% \end{figure}

% \paragraph{Text Detection.}
% \begin{itemize}
%     \item \textbf{Regression-based:} hồi quy trực tiếp hộp/tứ giác bao quanh vùng chữ.
%     \item \textbf{Connected component-based:} phát hiện thành phần ký tự (hoặc stroke) rồi liên kết thành dòng/từ.
%     \item \textbf{Segmentation-based:} dự đoán bản đồ pixel thuộc text, sau đó tách instance bằng hậu xử lý.
% \end{itemize}

% \paragraph{Text Recognition.}
% \begin{itemize}
%     \item \textbf{Segmentation-based:} tách ký tự (hoặc vùng con) rồi nhận dạng.
%     \item \textbf{Segmentation-free:} nhận dạng trực tiếp chuỗi (CTC/attention/transformer) không cần tách ký tự.
% \end{itemize}

% \paragraph{End-to-End Text Recognition.}
% \begin{itemize}
%     \item \textbf{One-stage:} phát hiện và nhận dạng trong một mô hình thống nhất.
%     \item \textbf{Two-stage:} phát hiện trước, sau đó cắt/chuẩn hóa và nhận dạng ở mô-đun thứ hai.
% \end{itemize}


% \section{Cơ sở lý thuyết}

% \subsection{Biểu diễn dữ liệu video và trích xuất khung hình}
% Video được xem như chuỗi khung hình (frame) theo thời gian.
% Cho video $V$, ta trích xuất tập khung hình $\{I_t\}_{t=1}^{T}$ với tốc độ lấy mẫu phù hợp (ví dụ: lấy mọi frame hoặc lấy theo bước nhảy để tối ưu tính toán).
% Vì văn bản có thể xuất hiện trong nhiều frame liên tiếp, dữ liệu video mang \textit{tính dư thừa theo thời gian} (temporal redundancy) có thể khai thác để tăng độ ổn định.

% \subsection{Quy trình xử lý tổng thể (Integrated Pipeline)}
% Pipeline đề xuất ở mức khái niệm gồm các bước:
% \begin{enumerate}
%     \item \textbf{Tiền xử lý (Pre-processing):}
%     \begin{itemize}
%         \item Giảm nhiễu, cân bằng sáng, tăng tương phản cục bộ khi cần thiết.
%         \item Giảm mờ do chuyển động (deblurring) hoặc tăng độ phân giải (super-resolution) cho vùng chữ nhỏ (tùy tài nguyên).
%         \item Ổn định video (video stabilization) trong trường hợp rung mạnh.
%     \end{itemize}

%     \item \textbf{Phát hiện vùng văn bản (Text Detection):}
%     Dự đoán vị trí vùng chữ theo dạng hộp (box), tứ giác (quadrilateral), đa giác (polygon) hoặc mặt nạ (segmentation mask).
%     Đầu ra gồm tập vùng $\mathcal{B}_t = \{b_{t}^{(i)}\}$ tại frame $I_t$.

%     \item \textbf{Chuẩn hóa hình học và cắt vùng chữ (Crop \& Rectify):}
%     Với vùng chữ nghiêng/cong, cần biến đổi phối cảnh hoặc chuẩn hóa hình học để đưa về ảnh chữ ``thẳng'' (rectified) trước khi nhận dạng.
%     Gọi ảnh vùng chữ sau chuẩn hóa là $\hat{I}_{t}^{(i)}$.

%     \item \textbf{Nhận dạng văn bản (Text Recognition):}
%     Mô hình nhận dạng thực hiện ánh xạ $\hat{I}_{t}^{(i)} \rightarrow \mathbf{s}_{t}^{(i)}$,
%     trong đó $\mathbf{s}_{t}^{(i)}$ là chuỗi ký tự dự đoán.

%     \item \textbf{Hậu xử lý (Post-processing):}
%     \begin{itemize}
%         \item Chuẩn hóa Unicode tiếng Việt, sửa lỗi dấu/telex nếu cần.
%         \item Loại bỏ ký tự nhiễu, lọc theo độ tin cậy (confidence).
%         \item Gộp các kết quả theo thời gian (temporal fusion) nếu cùng một biển hiệu xuất hiện ở nhiều frame.
%     \end{itemize}

%     \item \textbf{Suy luận loại dịch vụ/sản phẩm (Semantic Inference):}
%     Từ chuỗi ký tự $\mathbf{s}$, hệ thống gán nhãn ngành hàng/dịch vụ bằng:
%     (i) luật từ khóa (keyword rules), (ii) phân lớp văn bản (text classification), hoặc (iii) kết hợp NER + taxonomy.
% \end{enumerate}

% \subsection{Cơ sở lý thuyết Text Detection}
% Text Detection trong cảnh có thể chia thành các hướng chính:
% \begin{itemize}
%     \item \textbf{Regression-based:} dự đoán trực tiếp hộp/tứ giác bao quanh text.
%     \item \textbf{Connected-component based:} phát hiện thành phần ký tự và liên kết thành cụm.
%     \item \textbf{Segmentation-based:} dự đoán bản đồ pixel thuộc vùng text và tách instance bằng hậu xử lý.
% \end{itemize}
% Trong thực tế signboards, hướng segmentation-based phổ biến vì linh hoạt với chữ cong/biến dạng, nhưng gặp khó khi các cụm chữ nằm gần nhau gây chồng lấp.

% \subsection{Cơ sở lý thuyết Text Recognition}
% Text Recognition thường được mô hình hóa như bài toán nhận dạng chuỗi:
% \begin{itemize}
%     \item \textbf{CTC-based:} ánh xạ đặc trưng theo chiều ngang thành chuỗi ký tự với CTC loss.
%     \item \textbf{Attention/Encoder-Decoder:} sinh chuỗi theo cơ chế chú ý.
%     \item \textbf{Transformer-based recognizer:} tận dụng self-attention để học phụ thuộc dài và chống méo tốt hơn.
% \end{itemize}
% Với tiếng Việt, các yếu tố dấu và biến thể font làm tăng độ khó; hậu xử lý chuẩn hóa và từ điển miền (domain lexicon) có thể cải thiện độ chính xác.

% \subsection{Khai thác thông tin thời gian trong video}
% Khác ảnh tĩnh, video cho phép:
% \begin{itemize}
%     \item \textbf{Tracking text regions:} theo dõi một vùng chữ qua nhiều frame, giảm số lần chạy recognizer (nhận dạng một lần cho cả track).
%     \item \textbf{Temporal fusion:} hợp nhất nhiều kết quả nhận dạng theo vote/confidence/edit distance để tăng độ ổn định.
% \end{itemize}

% \section{Các nghiên cứu liên quan}

% \subsection{Bộ dữ liệu văn bản trong video lái xe: RoadText-1K}
% RoadText-1K giới thiệu bộ dữ liệu lớn cho bài toán phát hiện và nhận dạng văn bản trong video lái xe, gồm các đoạn clip được lấy mẫu từ dữ liệu lái xe thực tế và được gán nhãn dày (dense) theo từng frame.
% Bộ dữ liệu cung cấp:
% (i) bounding boxes cho vùng chữ, (ii) phiên âm (transcription), và (iii) nhãn phân loại text (ví dụ: tiếng Anh/không phải tiếng Anh/không đọc được), đồng thời tách riêng trường hợp biển số xe trong nhóm tiếng Anh.
% RoadText-1K được thiết kế theo hướng ``không thiên lệch theo text'' (unconstrained), phản ánh đúng bối cảnh camera hành trình với các nhiễu như motion blur, out-of-focus và glare.
% Các đánh giá baseline cho thấy các phương pháp SOTA trên ảnh tĩnh khi áp dụng vào video lái xe sẽ gặp suy giảm đáng kể do độ khó tăng lên.

% \subsection{Phương pháp phát hiện text theo cơ chế ``spotlight'': Spotlight Text Detector (STD)}
% Spotlight Text Detector (STD) tập trung giải quyết hai vấn đề lớn của text detection dạng segmentation:
% (i) các instance chữ nằm gần nhau gây chồng lấp khó tách, và (ii) hình dạng/độ dài chữ biến thiên lớn khiến mô hình khó khái quát.
% STD đề xuất hai thành phần chính:
% \begin{itemize}
%     \item \textbf{Spotlight Calibration Module (SCM):} hiệu chỉnh vùng ứng viên (candidate kernel) dựa trên coarse mask, tương tự cơ chế camera ``focus'' vào mục tiêu; module này giúp giảm false positives bằng cách hiệu chỉnh dự đoán và tăng khả năng tập trung vào vùng kernel quan trọng.
%     \item \textbf{Multivariate Information Extraction Module (MIEM):} trích xuất thông tin hình học đa dạng theo nhiều ``shape schemes'', nhằm học tốt hơn các đặc trưng tỷ lệ, hướng và hình dạng của chữ trong cảnh.
% \end{itemize}
% Kết quả thực nghiệm cho thấy STD đạt hiệu năng cạnh tranh/vượt trội trên nhiều benchmark text detection phổ biến (ICDAR2015, CTW1500, MSRA-TD500, Total-Text), đồng thời ablation chứng minh đóng góp của SCM và MIEM.

% \subsection{Liên hệ với đề tài khóa luận}
% Từ các nghiên cứu trên, có thể rút ra các định hướng quan trọng cho bài toán biển hiệu trong video street-view:
% \begin{itemize}
%     \item \textbf{Về dữ liệu và đánh giá:} cần ưu tiên bối cảnh ``unconstrained driving video'' và các dạng nhiễu đặc thù; RoadText-1K là nguồn tham khảo về cách thiết kế dữ liệu/nhãn và tiêu chí benchmark.
%     \item \textbf{Về phát hiện văn bản:} các phương pháp segmentation nâng cao cơ chế hiệu chỉnh/khoanh vùng (như SCM của STD) hữu ích khi text gần nhau và nền phức tạp --- đặc trưng thường gặp ở biển hiệu phố.
%     \item \textbf{Về pipeline tích hợp:} cần kết hợp (i) detection mạnh với chữ cong/biến dạng, (ii) rectify hợp lý trước recognition, và (iii) cơ chế temporal fusion/tracking để ổn định kết quả trên video.
% \end{itemize}

% \section{Tóm tắt chương}
% Chương này đã trình bày tổng quan bài toán đọc văn bản trên biển hiệu trong video đường phố, các thách thức đặc thù, cơ sở lý thuyết của hai thành phần chính (text detection và text recognition), cùng khả năng khai thác thông tin thời gian trong video.
% Ngoài ra, chương cũng tổng hợp hai hướng nghiên cứu liên quan tiêu biểu: bộ dữ liệu RoadText-1K cho video lái xe và phương pháp Spotlight Text Detector cho phát hiện chữ với cơ chế hiệu chỉnh vùng ứng viên.
% Những nội dung này là cơ sở để thiết kế pipeline tích hợp và xây dựng thực nghiệm trong các chương tiếp theo.
